# Visual Proof of the Universal Approximation Theorem for a Neural Network with a Single Hidden Layer

## Introduction

So what’s the goal ? The goal is to visually proof that we can approximate any arbitrary 3d function with a neural network, even when the network has just **one hidden layer**. 
A 3d function might look like this:

![image](https://user-images.githubusercontent.com/16619270/125162666-84d12400-e189-11eb-84b4-f3bc596d7d4d.png)

If we can do this we might then be able to extend this to n-dimensions (n means arbitrary many dimensions).

This has already been done for a neural network with 2 hidden layers and can be found here .
In order to be able to follow this writeup, it is beneficial if you are already familiar with the visual proof for a neural network with 2 hidden layers.
What we are trying to do now is to construct a visual proof when we can only use 1 hidden layer.
I couldn’t find a visual proof for this, however there exists a mathematical proof which uses functional analysis in order to proof this. 

![image](https://user-images.githubusercontent.com/16619270/127114845-320115f2-5f65-4135-89e8-0f631dd13052.png)


## Related Work

# A collapsible section with markdown
<details>
  <summary>Click to expand!</summary>
  
  ## Heading
  1. A numbered
  2. list
     * With some
     * Sub bullets
</details>
